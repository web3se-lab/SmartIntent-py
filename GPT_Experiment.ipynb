{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 1: Load the dataset and send requests to GPT</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# Read the content of the prompt file\n",
    "file_path = 'prompt.md'\n",
    "with open(file_path, 'r', encoding = 'utf-8') as file:\n",
    "    file_content = file.read()\n",
    "\n",
    "# You need to define your chat API and request headers here\n",
    "# chat_api_url = \n",
    "# chat_headers = {}\n",
    "\n",
    "# List of risk types\n",
    "risk_types = ['fee', 'disabletrading', 'blacklist', 'reflect', 'maxtx', 'mint', 'honeypot', 'reward', 'rebase', 'maxsell']\n",
    "\n",
    "# Function to fetch data from the data source API\n",
    "def fetch_data(key):\n",
    "    try:\n",
    "        url = f\"http://192.168.41.45:8081/data/intent?key={key}\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if 'sourceCode' in data and 'risk' in data:\n",
    "            print(f\"Key {key}:\")\n",
    "            risk_presence = {rtype: 0 for rtype in risk_types}\n",
    "            risk_types_list = []\n",
    "            for risk in data['risk']:\n",
    "                risk_type_lower = risk['type'].lower()\n",
    "                if risk_type_lower in risk_presence:\n",
    "                    risk_presence[risk_type_lower] = 1\n",
    "                    risk_types_list.append(risk_type_lower)\n",
    "            risk_presence_array = [risk_presence[rtype] for rtype in risk_types]\n",
    "            print(\"Real Ans:\", risk_types_list)\n",
    "            print(\"Real Ans Array:\", risk_presence_array)\n",
    "            return key, risk_types_list, risk_presence_array, data['sourceCode']\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request failed for key {key}: {e}\\n\")\n",
    "\n",
    "# Send the request to GPT\n",
    "def send_to_chat_api(source_code):\n",
    "    data = {\n",
    "        \"provider\": \"openai\",\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"prompts\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": file_content\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": source_code\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"top\": 0.5,\n",
    "        \"maxLength\": 4096\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(chat_api_url, headers=chat_headers, json=data)\n",
    "        response.raise_for_status()  # If the response status code is not 200, raise an HTTPError\n",
    "        response_data = response.json()\n",
    "        print(f\"GPT JSON: {response_data}\")\n",
    "\n",
    "        if response_data.get('status') == 1:\n",
    "            content = response_data['data']['content']\n",
    "            # Remove ```json\\n and ```\n",
    "            content = re.sub(r'```json\\n|```', '', content)  \n",
    "            content_json = json.loads(content)  # Convert string to dictionary or list\n",
    "\n",
    "            if isinstance(content_json, dict) and 'intents' in content_json:\n",
    "                intents = content_json['intents']  # Get the 'intents' list\n",
    "            elif isinstance(content_json, list):\n",
    "                intents = content_json\n",
    "            else:\n",
    "                intents = []\n",
    "\n",
    "            print(f\"GPT Response: {intents}\")\n",
    "\n",
    "            # Convert to lowercase for comparison\n",
    "            intents_lower = [intent.lower() for intent in intents]\n",
    "            risk_types_array = [1 if intent in intents_lower else 0 for intent in risk_types]\n",
    "\n",
    "            print(f\"GPT Response Array: {risk_types_array}\")\n",
    "            return response_data, intents, risk_types_array\n",
    "        else:\n",
    "            error_msg = response_data.get('msg', 'Unknown error')\n",
    "            raise Exception(f\"Error in GPT response: {error_msg}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        intents = []\n",
    "        risk_types_array = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        print(f\"GPT Response: {intents}\")\n",
    "        print(f\"GPT Response Array: {risk_types_array}\")\n",
    "        return {}, intents, risk_types_array\n",
    "\n",
    "# Save the result of a single key to a JSON file\n",
    "def save_to_json(key, real_ans, real_ans_array, gpt_json, gpt_response, gpt_response_array):\n",
    "    result = {\n",
    "        \"Key\": key,\n",
    "        \"Real Ans\": real_ans,\n",
    "        \"Real Ans Array\": real_ans_array,\n",
    "        \"GPT JSON\": gpt_json,\n",
    "        \"GPT Response\": gpt_response,\n",
    "        \"GPT Response Array\": gpt_response_array\n",
    "    }\n",
    "    filename = f'data_key_{key}.json'\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(result, json_file, ensure_ascii=False, indent=4)\n",
    "    print(f\"Data for key {key} saved to {filename}\\n\\n\")\n",
    "    return result\n",
    "\n",
    "# Progress bar\n",
    "def print_progress_bar(iteration, total, length=50):\n",
    "    percent = (\"{0:.1f}\").format(100 * (iteration / float(total)))\n",
    "    filled_length = int(length * iteration // total)\n",
    "    bar = '█' * filled_length + '-' * (length - filled_length)\n",
    "    print(f'\\rProgress: |{bar}| {percent}% Complete', end='\\r')\n",
    "    if iteration == total:\n",
    "        print()\n",
    "\n",
    "# Main program\n",
    "key = 20000\n",
    "all_data = []\n",
    "target_count = 10000\n",
    "\n",
    "while len(all_data) < target_count:\n",
    "    result = fetch_data(key)\n",
    "    if result is not None:\n",
    "        key, real_ans, real_ans_array, source_code = result\n",
    "        # Send sourceCode to the chat API and get the risk type array\n",
    "        gpt_json, gpt_response, gpt_response_array = send_to_chat_api(json.dumps(source_code))\n",
    "        record = save_to_json(key, real_ans, real_ans_array, gpt_json, gpt_response, gpt_response_array)\n",
    "        if record:\n",
    "            all_data.append(record)\n",
    "        completed_percentage = ((len(all_data)) / target_count) * 100\n",
    "        print_progress_bar(len(all_data), target_count)\n",
    "    key += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 2: Merge all JSON files</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_aggregate_data(start_key, num_files, output_file):\n",
    "    all_data = []\n",
    "    key = start_key\n",
    "    valid_file_count = 0\n",
    "    counter = 0\n",
    "\n",
    "    while valid_file_count < num_files:\n",
    "        filename = f'data_key_{key}.json'\n",
    "        try:\n",
    "            with open(filename, 'r', encoding='utf-8') as json_file:\n",
    "                data = json.load(json_file)\n",
    "                all_data.append(data)\n",
    "                valid_file_count += 1\n",
    "                if \"GPT JSON\" in data and data[\"GPT JSON\"] == {}:  # If GPT JSON is empty, re-fetch data\n",
    "                    counter = counter + 1\n",
    "                    print(\"Invalid key:\", key)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {filename} not found, skipping.\")\n",
    "        \n",
    "        key += 1\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(all_data, json_file, ensure_ascii = False, indent = 4)\n",
    "    print(f\"Aggregated data saved to {output_file}\")\n",
    "    print(\"400 occurs\", counter, \"times!\")\n",
    "\n",
    "# Main program\n",
    "start_key = 20000\n",
    "num_files = 10000\n",
    "output_file = 'gpt_experiment.json'\n",
    "\n",
    "load_and_aggregate_data(start_key, num_files, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 3: Handle 400 errors</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content of the prompt file and assign it to a variable string\n",
    "file_path = 'prompt.md'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    file_content = file.read()\n",
    "\n",
    "# Function to fetch data from the data source API\n",
    "def fetch_data(key):\n",
    "    try:\n",
    "        url = f\"http://192.168.41.45:8081/data/intent?key={key}\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if 'sourceCode' in data and 'risk' in data:\n",
    "            print(f\"Key {key}:\")\n",
    "            risk_presence = {rtype: 0 for rtype in risk_types}\n",
    "            risk_types_list = []\n",
    "            for risk in data['risk']:\n",
    "                risk_type_lower = risk['type'].lower()\n",
    "                if risk_type_lower in risk_presence:\n",
    "                    risk_presence[risk_type_lower] = 1\n",
    "                    risk_types_list.append(risk_type_lower)\n",
    "            risk_presence_array = [risk_presence[rtype] for rtype in risk_types]\n",
    "            print(\"Real Ans:\", risk_types_list)\n",
    "            print(\"Real Ans Array:\", risk_presence_array)\n",
    "            return key, risk_types_list, risk_presence_array, data['sourceCode']\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request failed for key {key}: {e}\\n\")   \n",
    "\n",
    "# Function to send a request to the GPT API\n",
    "def send_to_chat_api(source_code):\n",
    "    data = {\n",
    "        \"provider\": \"openai\",\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"prompts\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": file_content\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": source_code\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"top\": 0.5,\n",
    "        \"maxLength\": 4096\n",
    "    }\n",
    "\n",
    "    trial = 1\n",
    "    total_trial = 5\n",
    "\n",
    "    while True:\n",
    "        trial = trial + 1\n",
    "        try:\n",
    "            response = requests.post(chat_api_url, headers=chat_headers, json=data)\n",
    "            response.raise_for_status()\n",
    "            response_data = response.json()\n",
    "            print(f\"GPT JSON: {response_data}\")\n",
    "\n",
    "            if response_data.get('status') == 1:\n",
    "                content = response_data['data']['content']\n",
    "                content_json = json.loads(content)\n",
    "\n",
    "                if isinstance(content_json, dict) and 'intents' in content_json:\n",
    "                    intents = content_json['intents']\n",
    "                elif isinstance(content_json, list):\n",
    "                    intents = content_json\n",
    "                else:\n",
    "                    intents = []\n",
    "\n",
    "                print(f\"GPT Response: {intents}\")\n",
    "\n",
    "                intents_lower = [intent.lower() for intent in intents]\n",
    "                risk_types_array = [1 if intent in intents_lower else 0 for intent in risk_types]\n",
    "\n",
    "                print(f\"GPT Response Array: {risk_types_array}\")\n",
    "                return response_data, intents, risk_types_array\n",
    "            else:\n",
    "                error_msg = response_data.get('msg', 'Unknown error')\n",
    "                raise Exception(f\"Error in GPT response: {error_msg}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "\n",
    "            if \"429\" in str(e):\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "            elif trial <= total_trial:\n",
    "                # time.sleep(1)\n",
    "                continue\n",
    "            else:\n",
    "                intents = []\n",
    "                risk_types_array = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "                print(f\"GPT Response: {intents}\")\n",
    "                print(f\"GPT Response Array: {risk_types_array}\")\n",
    "                return {}, intents, risk_types_array\n",
    "\n",
    "# Save the result of a single key to a JSON file\n",
    "def save_to_json(key, real_ans, real_ans_array, gpt_json, gpt_response, gpt_response_array):\n",
    "    result = {\n",
    "        \"Key\": key,\n",
    "        \"Real Ans\": real_ans,\n",
    "        \"Real Ans Array\": real_ans_array,\n",
    "        \"GPT JSON\": gpt_json,\n",
    "        \"GPT Response\": gpt_response,\n",
    "        \"GPT Response Array\": gpt_response_array\n",
    "    }\n",
    "    filename = f'data_key_{key}.json'\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(result, json_file, ensure_ascii=False, indent=4)\n",
    "    print(f\"Data for key {key} saved to {filename}\\n\\n\")\n",
    "    return result\n",
    "\n",
    "# Progress bar function\n",
    "def print_progress_bar(iteration, total, length=50):\n",
    "    percent = (\"{0:.1f}\").format(100 * (iteration / float(total)))\n",
    "    filled_length = int(length * iteration // total)\n",
    "    bar = '█' * filled_length + '-' * (length - filled_length)\n",
    "    print(f'\\rProgress: |{bar}| {percent}% Complete', end='\\r')\n",
    "    if iteration == total:\n",
    "        print()\n",
    "\n",
    "# Main program\n",
    "key = 20000\n",
    "all_data = []\n",
    "total_files = 30010 - 20000\n",
    "processed_files = 0\n",
    "\n",
    "# Loop through all files from 20000 to 30009\n",
    "for key in range(key, key + total_files):  \n",
    "    filename = f'data_key_{key}.json'\n",
    "    \n",
    "    if os.path.exists(filename):  # Check if the file exists\n",
    "        with open(filename, 'r', encoding='utf-8') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            if \"GPT JSON\" in data and data[\"GPT JSON\"] == {}:  # If GPT JSON is empty, re-fetch data\n",
    "                result = fetch_data(key)\n",
    "                if result is not None:\n",
    "                    key, real_ans, real_ans_array, source_code = result\n",
    "                    # Send sourceCode to the chat API and get the risk type array\n",
    "                    gpt_json, gpt_response, gpt_response_array = send_to_chat_api(json.dumps(json.dumps(source_code)))  # Send sourceCode to the chat API and get the risk type array\n",
    "                    save_to_json(key, data['Real Ans'], data['Real Ans Array'], gpt_json, gpt_response, gpt_response_array)  # Save data to a JSON file\n",
    "    else:\n",
    "        print(f\"File {filename} does not exist, skipping...\\n\")  # If the file does not exist, skip this file\n",
    "    \n",
    "    processed_files += 1\n",
    "    print_progress_bar(processed_files, total_files)  # Update the progress bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 4: Evaluate the performance of GPT</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load data from the gpt_test.json file\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Compute and print evaluation metrics\n",
    "def evaluate(data):\n",
    "    y_true = [item[\"Real Ans Array\"] for item in data]\n",
    "    y_pred = [item[\"GPT Response Array\"] for item in data]\n",
    "\n",
    "    print(len(y_true), len(y_pred))\n",
    "    \n",
    "    # Flatten the 2D arrays to 1D arrays for use with Keras evaluation functions\n",
    "    y_true_flat = [label for sublist in y_true for label in sublist]\n",
    "    y_pred_flat = [label for sublist in y_pred for label in sublist]\n",
    "\n",
    "    # Convert to TensorFlow tensors\n",
    "    y_true_tensor = tf.convert_to_tensor(y_true_flat, dtype=tf.float32)\n",
    "    y_pred_tensor = tf.convert_to_tensor(y_pred_flat, dtype=tf.float32)\n",
    "\n",
    "    # Use Keras evaluation functions to compute the metrics\n",
    "    accuracy = tf.keras.metrics.BinaryAccuracy()(y_true_tensor, y_pred_tensor)\n",
    "    precision = tf.keras.metrics.Precision()(y_true_tensor, y_pred_tensor)\n",
    "    recall = tf.keras.metrics.Recall()(y_true_tensor, y_pred_tensor)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    print(\"==========================================================\")\n",
    "    print(\"Total\")\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy.numpy())\n",
    "    print(\"Precision:\", precision.numpy())\n",
    "    print(\"Recall:\", recall.numpy())\n",
    "    print(\"F1 Score:\", f1.numpy())\n",
    "    print(\"==========================================================\")\n",
    "\n",
    "# Main program logic\n",
    "file_path = 'gpt_experiment.json'  # Replace with your file path\n",
    "data = load_data(file_path)\n",
    "evaluate(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
